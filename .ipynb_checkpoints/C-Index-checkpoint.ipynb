{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac82c26-0b25-4ee1-9c58-c63245456730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "def getReciprocal(n, d):\n",
    "    if n != 0:\n",
    "        return d/n\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "class Author(object):\n",
    "    \"\"\"\n",
    "    A class to represent an author and their metadata.\n",
    "\n",
    "    Attributes:\n",
    "        firstName (str): The author's first name.\n",
    "        lastName (str): The author's last name.\n",
    "        country (str): The author's affiliation country.\n",
    "        country_code (str): The author's affiliation country code (e.g., 'USA').\n",
    "        city (str): The author's affiliation city.\n",
    "        gender (str): The author's gender.\n",
    "        paperList (list): A list of publication IDs the author has contributed to.\n",
    "        specialization (str): The author's field of study.\n",
    "    \"\"\"\n",
    "    def __init__(self, paper, first, last, country, country_code, aff_city, gender, specialization):\n",
    "        self.firstName = first\n",
    "        self.lastName = last\n",
    "        self.country = country\n",
    "        self.country_code = country_code\n",
    "        self.city = aff_city\n",
    "        self.gender = gender\n",
    "        self.paperList = []\n",
    "        self.specialization = specialization\n",
    "        if paper:\n",
    "            self.paperList.append(paper)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Defines two authors as equal if their key metadata attributes match.\n",
    "        Equality is based on name, gender, country code, and specialization.\n",
    "        \"\"\"\n",
    "        if (isinstance(other, Author)):\n",
    "            # Using your full equality check\n",
    "            return (self.firstName == other.firstName and\n",
    "                    self.lastName == other.lastName and\n",
    "                    self.gender == other.gender and\n",
    "                    self.country_code == other.country_code and\n",
    "                    self.specialization == other.specialization)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Generates a hash for the Author object.\n",
    "        Note: The hash should be based on the same attributes used in __eq__.\n",
    "        \"\"\"\n",
    "        return hash((self.firstName, self.lastName, self.gender, \n",
    "                     self.country_code, self.specialization))\n",
    "        \n",
    "    def getName(self):\n",
    "        return self.firstName + \" \" + self.lastName\n",
    "\n",
    "def collectAuthorsOfOnePaper(df, pub_id, **kwargs):\n",
    "    \"\"\"\n",
    "    Retrieves all authors of a specific paper from the main DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The main dataframe of publications.\n",
    "        pub_id (str): The unique identifier for the paper.\n",
    "        **kwargs:\n",
    "            refAuthor (Author, optional): An author to exclude from the list.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Author objects who co-authored the paper.\n",
    "    \"\"\"\n",
    "    refAuthor = kwargs.get('refAuthor', None)\n",
    "    authorList = []\n",
    "    # Using your logic to iterate from a start point if provided, but simplifying for general case\n",
    "    paper_df = df[df['pub_id'] == pub_id]\n",
    "    for _, row in paper_df.iterrows():\n",
    "        author = Author(\n",
    "            row[\"pub_id\"], row[\"first_name\"], row[\"last_name\"],\n",
    "            row[\"aff_country\"], row[\"aff_country_code\"], row[\"aff_city\"],\n",
    "            row[\"gender\"], row[\"specialization\"]\n",
    "        )\n",
    "        if (author != refAuthor):\n",
    "            authorList.append(author)\n",
    "    return authorList\n",
    "\n",
    "def searchAuthorPapers(df, author):\n",
    "    \"\"\"\n",
    "    Retrieves all authors of a specific paper from the main DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The main dataframe of publications.\n",
    "        pub_id (str): The unique identifier for the paper.\n",
    "        **kwargs:\n",
    "            refAuthor (Author, optional): An author to exclude from the list.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Author objects who co-authored the paper.\n",
    "    \"\"\"\n",
    "    paperDict = {}\n",
    "    # Find all rows in the dataframe corresponding to the reference author\n",
    "    author_rows = df[(df['first_name'] == author.firstName) & (df['last_name'] == author.lastName)]\n",
    "    # For each unique paper they wrote...\n",
    "    for pub_id in author_rows['pub_id'].unique():\n",
    "        # ...find all their collaborators on that paper.\n",
    "        authorList = collectAuthorsOfOnePaper(df, pub_id, refAuthor=author)\n",
    "        clean_pub_id = pub_id.replace(\"pub.\", \"\")\n",
    "        paperDict[clean_pub_id] = authorList\n",
    "    return paperDict\n",
    "\n",
    "def create_graph(dict_x, **kwargs):\n",
    "    \"\"\"\n",
    "    Creates a NetworkX graph from a dictionary of collaborations.\n",
    "\n",
    "    Args:\n",
    "        dict_x (dict): A dictionary where keys are nodes (e.g., paper IDs) and\n",
    "                       values are lists of nodes they connect to (e.g., authors).\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: A NetworkX graph object representing the collaboration network.\n",
    "    \"\"\"\n",
    "    # Using your original graph creation logic\n",
    "    refAuthor = kwargs.get('refAuthor', None)\n",
    "    if refAuthor != None:\n",
    "        for key in dict_x.keys():\n",
    "            dict_x[key].append(refAuthor)\n",
    "    G = nx.from_dict_of_lists(dict_x)\n",
    "    return G\n",
    "\n",
    "def binaryCalculation(refAuthorFeature, collabFeature, baseFactor):\n",
    "    if refAuthorFeature == collabFeature and baseFactor != 0:\n",
    "        return 1/baseFactor\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processCategoricalCalculation(collabCategory, baseFactor, countDict):\n",
    "    if collabCategory not in countDict.keys():\n",
    "        countDict[collabCategory] = baseFactor\n",
    "    else:\n",
    "        countDict[collabCategory] += baseFactor\n",
    "\n",
    "def isWeightedCalculation(authorCategory, categoricalWeights):\n",
    "    if categoricalWeights is not None:\n",
    "        weightedCategories = {j for i in categoricalWeights.values() for j in i}\n",
    "        if authorCategory in list(weightedCategories):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def calculateCIndex(author, collabDict, collabGraph, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculates the 'Community Index' (C-Index) for a single author.\n",
    "\n",
    "    This index is an aggregation of diversity scores across three dimensions:\n",
    "    gender, nationality, and specialization. The score for each paper is calculated,\n",
    "    and the final index is the average across all of an author's papers.\n",
    "\n",
    "    The calculation can optionally include a bonus for collaborating with \"new\" authors,\n",
    "    defined as authors who have only appeared on one paper in the reference author's network.\n",
    "\n",
    "    Args:\n",
    "        author (Author): The reference author for whom the index is calculated.\n",
    "        collabDict (dict): The author's collaboration dictionary from searchAuthorPapers.\n",
    "        collabGraph (nx.Graph): The author's collaboration network graph.\n",
    "        **kwargs:\n",
    "            crossPaper (bool): If True, apply a bonus for new collaborators.\n",
    "            newBonus (float): The bonus multiplier for new collaborators.\n",
    "            baseGenderFactor (float): Base weight for gender diversity calculation.\n",
    "            baseNationalityBonus (float): Base weight for nationality diversity.\n",
    "            baseSpecializationFactor (float): Base weight for specialization diversity.\n",
    "            categoricalWeights (dict): Optional weights for specific countries or fields.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (rounded final index, unrounded final index, detailed report list)\n",
    "    \"\"\"\n",
    "    # --- Parameter Setup ---\n",
    "    crossPaper = kwargs.get('crossPaper', False)\n",
    "    newBonus = kwargs.get('newBonus', 0.8)\n",
    "    # The 'isNew' parameter defines a \"new\" collaborator by their degree in the graph.\n",
    "    # A degree of 1 means they only appear on one paper in this author's network.\n",
    "    isNew = 1 \n",
    "\n",
    "    # Base factors for diversity calculations\n",
    "    baseGenderFactor = kwargs.get('baseGenderFactor', 1)\n",
    "    baseNationalityBonus = kwargs.get('baseNationalityBonus', 1)\n",
    "    baseSpecializationFactor = kwargs.get('baseSpecializationFactor', 1)\n",
    "    categoricalWeights = kwargs.get('categoricalWeights', None)\n",
    "\n",
    "    paperFeatureIndices = []\n",
    "    paper_details_for_reporting = [] \n",
    "\n",
    "    # --- Calculation Loop: Iterate through each paper the author has written ---\n",
    "    for publication in collabDict.keys():\n",
    "        # Initialize diversity scores for this specific paper\n",
    "        # Gender: Starts with the author's own contribution\n",
    "        genderFactor = 1 * baseGenderFactor\n",
    "        # Nationality/Specialization: Track counts of each category\n",
    "        nationalityBonus = 0\n",
    "        nationalityCounts = {author.country_code : 1 * baseNationalityBonus}\n",
    "        specializationFactor = 0\n",
    "        specializationCounts = {author.specialization : 1 * baseSpecializationFactor}\n",
    "\n",
    "        # --- Loop through collaborators on this paper ---\n",
    "        for collab in collabDict[publication]:\n",
    "            bonus = 1\n",
    "            # Apply a bonus if the collaborator is \"new\" to the network            \n",
    "            if collabGraph.degree[collab] == isNew and crossPaper == True:\n",
    "                bonus += newBonus\n",
    "            \n",
    "            # --- Update diversity scores based on this collaborator ---\n",
    "            # Gender: Adds to the score if genders are different\n",
    "            genderFactor += binaryCalculation(author.gender, collab.gender, baseGenderFactor*bonus)\n",
    "            # Nationality & Specialization: Tally the counts for each category\n",
    "            processCategoricalCalculation(collab.country_code,\n",
    "                                          baseNationalityBonus*bonus,\n",
    "                                          nationalityCounts)\n",
    "            processCategoricalCalculation(collab.specialization,\n",
    "                                          baseSpecializationFactor*bonus,\n",
    "                                          specializationCounts)\n",
    "\n",
    "        # --- Finalize Diversity Factors for THIS paper ---\n",
    "        # The logic combines two ideas:\n",
    "        # 1. Variety: The number of unique categories (e.g., `len(set(nationalityCounts.keys()))`)\n",
    "        # 2. Balance: A weight that rewards even distribution and penalizes self-concentration.\n",
    "\n",
    "        # Gender Factor: A simple reciprocal of the sum.       \n",
    "        final_gender_factor = getReciprocal(genderFactor, len(collabDict[publication]))\n",
    "        # Nationality Factor        \n",
    "        nationality_denominator = sum(nationalityCounts.values()) - baseNationalityBonus\n",
    "        nationality_weight = getReciprocal(nationalityCounts.get(author.country_code, 0), nationality_denominator)\n",
    "        final_nationality_factor = len(set(nationalityCounts.keys())) * nationality_weight\n",
    "\n",
    "        # Specialization Factor\n",
    "        specialization_denominator = sum(specializationCounts.values()) - baseSpecializationFactor\n",
    "        specialization_weight = getReciprocal(specializationCounts.get(author.specialization, 0), specialization_denominator)\n",
    "        final_specialization_factor = len(set(specializationCounts.keys())) * specialization_weight\n",
    "        \n",
    "        # Apply any specific external weights (e.g., for underrepresented countries)\n",
    "        if isWeightedCalculation(author.country_code, categoricalWeights):\n",
    "            final_nationality_factor *= categoricalWeights[\"nationality\"][author.country_code]\n",
    "        if isWeightedCalculation(author.specialization, categoricalWeights):\n",
    "            final_specialization_factor *= categoricalWeights[\"specialization\"][author.specialization]\n",
    "        \n",
    "        # The index for this paper is the sum of the three diversity factors\n",
    "        paper_index = final_gender_factor + final_nationality_factor + final_specialization_factor\n",
    "        paperFeatureIndices.append(paper_index)\n",
    "\n",
    "        # Store detailed results for reporting\n",
    "        paper_details_for_reporting.append({\n",
    "            \"pub_id\": f\"pub.{publication}\",\n",
    "            \"Gender Factor\": final_gender_factor,\n",
    "            \"Nationality Factor\": final_nationality_factor,\n",
    "            \"Specialization Factor\": final_specialization_factor,\n",
    "            \"Paper Index\": paper_index\n",
    "        })\n",
    "    \n",
    "    # --- Aggregate across all papers ---\n",
    "    # The final D-Index is the average of the paper indices.        \n",
    "    unrounded_index = sum(paperFeatureIndices) / len(paperFeatureIndices)\n",
    "    final_index = round(sum(paperFeatureIndices) / len(paperFeatureIndices))\n",
    "    return final_index, unrounded_index, paper_details_for_reporting\n",
    "\n",
    "\n",
    "def find_best_example_authors(df):\n",
    "    \"\"\"\n",
    "    Analyzes the dataframe to find authors with high and low collaborator repeat rates.\n",
    "    Returns the names of the best candidates for demonstration.\n",
    "    \"\"\"\n",
    "    unique_authors = df.drop_duplicates(subset=['first_name', 'last_name'])\n",
    "    author_stats = []\n",
    "    for _, author_row in unique_authors.iterrows():\n",
    "        temp_author = Author(None, author_row.first_name, author_row.last_name, None, None, None, None, None)\n",
    "        papers = searchAuthorPapers(df, temp_author)\n",
    "        if len(papers) < 2: continue # Focus on authors with multiple papers for better patterns\n",
    "        all_collaborators = [collab.getName() for sublist in papers.values() for collab in sublist]\n",
    "        if not all_collaborators: continue\n",
    "        num_unique_collaborators = len(set(all_collaborators))\n",
    "        avg_repeat_rate = len(all_collaborators) / num_unique_collaborators\n",
    "        author_stats.append({\"name\": temp_author.getName(), \"avg_repeat_rate\": avg_repeat_rate})\n",
    "\n",
    "    if not author_stats: return None, None\n",
    "    sorted_stats = sorted(author_stats, key=lambda x: x['avg_repeat_rate'])\n",
    "    high_newness_author_name = sorted_stats[0]['name']   # Low repeat rate -> high newness\n",
    "    high_repeat_author_name = sorted_stats[-1]['name'] # High repeat rate\n",
    "    return high_repeat_author_name, high_newness_author_name\n",
    "\n",
    "\n",
    "def generate_comparison_report(author, df):\n",
    "    \"\"\"\n",
    "    Generates and prints a formatted report for a given author, comparing\n",
    "    C-Index with and without the cross-paper new author bonus\n",
    "    \"\"\"\n",
    "    print(\"-\" * 95)\n",
    "    print(f\"C-Index Comparison Report for: {author.getName()} ({author.specialization})\")\n",
    "    print(\"-\" * 95)\n",
    "\n",
    "    papers_dict = searchAuthorPapers(df, author)\n",
    "    # The graph must be created from the author list *without* the refAuthor for degree to be correct\n",
    "    graph_for_degree_check = create_graph(papers_dict)\n",
    "\n",
    "    # --- Run calculations ---\n",
    "    index_no_bonus, details_no_bonus = calculateCIndex(author, papers_dict, graph_for_degree_check, crossPaper=False)\n",
    "    index_with_bonus, details_with_bonus = calculateCIndex(author, papers_dict, graph_for_degree_check, crossPaper=True)\n",
    "\n",
    "    print(f\"Overall C-Index (No Bonus): {index_no_bonus}\")\n",
    "    print(f\"Overall C-Index (With New Author Bonus): {index_with_bonus}\\n\")\n",
    "    print(\"Detailed Breakdown (Displaying values with bonus applied):\")\n",
    "    header = f\"{'Pub ID':<17} | {'Gender':>12} | {'Nationality':>15} | {'Specialization':>16} | {'Paper Index':>15}\"\n",
    "    print(header); print(\"-\" * len(header))\n",
    "    no_bonus_indices = {d['pub_id']: d['Paper Index'] for d in details_no_bonus}\n",
    "\n",
    "    for paper_detail in details_with_bonus:\n",
    "        pub_id = paper_detail['pub_id']\n",
    "        note = \"<- Bonus Applied\" if abs(paper_detail['Paper Index'] - no_bonus_indices.get(pub_id, 0)) > 0.01 else \"\"\n",
    "        row = (f\"{pub_id:<17} | {paper_detail['Gender Factor']:>12.2f} | \"\n",
    "               f\"{paper_detail['Nationality Factor']:>15.2f} | {paper_detail['Specialization Factor']:>16.2f} | \"\n",
    "               f\"{paper_detail['Paper Index']:>15.2f} {note}\")\n",
    "        print(row)\n",
    "    print(\"-\" * 95 + \"\\n\")\n",
    "\n",
    "\n",
    "def generate_full_paper_report(pub_id, df):\n",
    "    \"\"\"\n",
    "    Finds every author on a given paper and generates a C-Index report for each one.\n",
    "    This is used to create comprehensive summary tables.\n",
    "    \"\"\"\n",
    "    print(f\"\\n\\n{'='*45}\")\n",
    "    print(f\" Full C-Index Report for All Authors on: {pub_id}\")\n",
    "    print(f\"{'='*45}\\n\")\n",
    "\n",
    "    authors_on_paper = collectAuthorsOfOnePaper(df, pub_id)\n",
    "\n",
    "    if not authors_on_paper:\n",
    "        print(f\"No authors found for {pub_id} or paper does not exist.\")\n",
    "        return\n",
    "\n",
    "    for author in authors_on_paper:\n",
    "        generate_comparison_report(author, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a7614e-4e9f-43db-921f-b6c412af0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_for_author_cohort(author_cohort, df):\n",
    "    \"\"\"\n",
    "    Generates a single, author-centric table for a specific, predefined\n",
    "    list of author objects, showing all papers for each of them.\n",
    "    This version uses the UNROUNDED baseline c-index.\n",
    "    \"\"\"\n",
    "    all_rows_data = []\n",
    "\n",
    "    print(f\"Building table for a cohort of {len(author_cohort)} authors...\")\n",
    "\n",
    "    # Loop through each hand-picked author\n",
    "    for author in author_cohort:\n",
    "        # Calculate their profile based on their full history\n",
    "        papers_dict = searchAuthorPapers(df, author)\n",
    "        if not papers_dict: continue # Skip if author has no other papers found\n",
    "\n",
    "        graph = create_graph(papers_dict)\n",
    "\n",
    "        # <<< CHANGE 1: Capture the EXACT (unrounded) baseline c-index >>>\n",
    "        # The second return value from calculateCIndex is the unrounded float.\n",
    "        _, c_index_baseline_exact, _ = calculateCIndex(author, papers_dict, graph, crossPaper=False)\n",
    "        _, c_index_bonus_exact, details_bonus = calculateCIndex(author, papers_dict, graph, crossPaper=True)\n",
    "\n",
    "        # Now, create a row for EACH paper this author has written\n",
    "        for paper_details in details_bonus:\n",
    "            row_data = {\n",
    "                'Pub id': paper_details['pub_id'].replace(\"pub.\", \"\"),\n",
    "                'Name': author.firstName,\n",
    "                'Country': author.country,\n",
    "                'Gender': 'M' if author.gender == 'male' else 'F',\n",
    "                'Field': author.specialization.replace(\"Science\", \"Sci\").replace(\"Healthcare\", \"Health\"),\n",
    "                'c-index (Bonus)': c_index_bonus_exact,\n",
    "                'Country factor': paper_details['Nationality Factor'],\n",
    "                'Gender factor': paper_details['Gender Factor'],\n",
    "                'Field factor': paper_details['Specialization Factor'],\n",
    "                'Paper factor': paper_details['Paper Index'],\n",
    "                # <<< CHANGE 2: Use the exact baseline c-index in the data >>>\n",
    "                'c-index (Baseline)': c_index_baseline_exact,\n",
    "            }\n",
    "            all_rows_data.append(row_data)\n",
    "\n",
    "    if not all_rows_data:\n",
    "        print(\"No data to generate.\")\n",
    "        return None\n",
    "\n",
    "    # Create and format the final DataFrame\n",
    "    final_df = pd.DataFrame(all_rows_data)\n",
    "    final_df.rename(columns={'c-index (Bonus)': 'c-index', 'c-index (Baseline)': 'c-index '}, inplace=True)\n",
    "    final_df.sort_values(by=['Name', 'Pub id'], inplace=True)\n",
    "\n",
    "    # Use Pandas Styler to format the output for display\n",
    "    # <<< CHANGE 3: Add formatting for the baseline c-index column >>>\n",
    "    styled_df = final_df.style.format({\n",
    "        'c-index': \"{:.2f}\",\n",
    "        'c-index ': \"{:.2f}\", # Format the baseline c-index to 2 decimal places\n",
    "        'Country factor': \"{:.2f}\",\n",
    "        'Gender factor': \"{:.2f}\",\n",
    "        'Field factor': \"{:.2f}\",\n",
    "        'Paper factor': \"{:.2f}\",\n",
    "    }).set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "\n",
    "    return styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5847a2d7-cf2c-424b-82df-9510ffd2949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building a focused table based on a specific author cohort ---\n",
      "Selected 6 authors from paper 'pub.1123345821': ['Adam Smith', 'Emily Johnson', 'Robert Brown', 'Maria Garcia', 'David Williams', 'Sophia Davis']\n",
      "\n",
      "Building table for a cohort of 6 authors...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b4ec6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b4ec6_row0_col0, #T_b4ec6_row0_col1, #T_b4ec6_row0_col2, #T_b4ec6_row0_col3, #T_b4ec6_row0_col4, #T_b4ec6_row0_col5, #T_b4ec6_row0_col6, #T_b4ec6_row0_col7, #T_b4ec6_row0_col8, #T_b4ec6_row0_col9, #T_b4ec6_row0_col10, #T_b4ec6_row1_col0, #T_b4ec6_row1_col1, #T_b4ec6_row1_col2, #T_b4ec6_row1_col3, #T_b4ec6_row1_col4, #T_b4ec6_row1_col5, #T_b4ec6_row1_col6, #T_b4ec6_row1_col7, #T_b4ec6_row1_col8, #T_b4ec6_row1_col9, #T_b4ec6_row1_col10, #T_b4ec6_row2_col0, #T_b4ec6_row2_col1, #T_b4ec6_row2_col2, #T_b4ec6_row2_col3, #T_b4ec6_row2_col4, #T_b4ec6_row2_col5, #T_b4ec6_row2_col6, #T_b4ec6_row2_col7, #T_b4ec6_row2_col8, #T_b4ec6_row2_col9, #T_b4ec6_row2_col10, #T_b4ec6_row3_col0, #T_b4ec6_row3_col1, #T_b4ec6_row3_col2, #T_b4ec6_row3_col3, #T_b4ec6_row3_col4, #T_b4ec6_row3_col5, #T_b4ec6_row3_col6, #T_b4ec6_row3_col7, #T_b4ec6_row3_col8, #T_b4ec6_row3_col9, #T_b4ec6_row3_col10, #T_b4ec6_row4_col0, #T_b4ec6_row4_col1, #T_b4ec6_row4_col2, #T_b4ec6_row4_col3, #T_b4ec6_row4_col4, #T_b4ec6_row4_col5, #T_b4ec6_row4_col6, #T_b4ec6_row4_col7, #T_b4ec6_row4_col8, #T_b4ec6_row4_col9, #T_b4ec6_row4_col10, #T_b4ec6_row5_col0, #T_b4ec6_row5_col1, #T_b4ec6_row5_col2, #T_b4ec6_row5_col3, #T_b4ec6_row5_col4, #T_b4ec6_row5_col5, #T_b4ec6_row5_col6, #T_b4ec6_row5_col7, #T_b4ec6_row5_col8, #T_b4ec6_row5_col9, #T_b4ec6_row5_col10, #T_b4ec6_row6_col0, #T_b4ec6_row6_col1, #T_b4ec6_row6_col2, #T_b4ec6_row6_col3, #T_b4ec6_row6_col4, #T_b4ec6_row6_col5, #T_b4ec6_row6_col6, #T_b4ec6_row6_col7, #T_b4ec6_row6_col8, #T_b4ec6_row6_col9, #T_b4ec6_row6_col10, #T_b4ec6_row7_col0, #T_b4ec6_row7_col1, #T_b4ec6_row7_col2, #T_b4ec6_row7_col3, #T_b4ec6_row7_col4, #T_b4ec6_row7_col5, #T_b4ec6_row7_col6, #T_b4ec6_row7_col7, #T_b4ec6_row7_col8, #T_b4ec6_row7_col9, #T_b4ec6_row7_col10, #T_b4ec6_row8_col0, #T_b4ec6_row8_col1, #T_b4ec6_row8_col2, #T_b4ec6_row8_col3, #T_b4ec6_row8_col4, #T_b4ec6_row8_col5, #T_b4ec6_row8_col6, #T_b4ec6_row8_col7, #T_b4ec6_row8_col8, #T_b4ec6_row8_col9, #T_b4ec6_row8_col10, #T_b4ec6_row9_col0, #T_b4ec6_row9_col1, #T_b4ec6_row9_col2, #T_b4ec6_row9_col3, #T_b4ec6_row9_col4, #T_b4ec6_row9_col5, #T_b4ec6_row9_col6, #T_b4ec6_row9_col7, #T_b4ec6_row9_col8, #T_b4ec6_row9_col9, #T_b4ec6_row9_col10, #T_b4ec6_row10_col0, #T_b4ec6_row10_col1, #T_b4ec6_row10_col2, #T_b4ec6_row10_col3, #T_b4ec6_row10_col4, #T_b4ec6_row10_col5, #T_b4ec6_row10_col6, #T_b4ec6_row10_col7, #T_b4ec6_row10_col8, #T_b4ec6_row10_col9, #T_b4ec6_row10_col10, #T_b4ec6_row11_col0, #T_b4ec6_row11_col1, #T_b4ec6_row11_col2, #T_b4ec6_row11_col3, #T_b4ec6_row11_col4, #T_b4ec6_row11_col5, #T_b4ec6_row11_col6, #T_b4ec6_row11_col7, #T_b4ec6_row11_col8, #T_b4ec6_row11_col9, #T_b4ec6_row11_col10, #T_b4ec6_row12_col0, #T_b4ec6_row12_col1, #T_b4ec6_row12_col2, #T_b4ec6_row12_col3, #T_b4ec6_row12_col4, #T_b4ec6_row12_col5, #T_b4ec6_row12_col6, #T_b4ec6_row12_col7, #T_b4ec6_row12_col8, #T_b4ec6_row12_col9, #T_b4ec6_row12_col10, #T_b4ec6_row13_col0, #T_b4ec6_row13_col1, #T_b4ec6_row13_col2, #T_b4ec6_row13_col3, #T_b4ec6_row13_col4, #T_b4ec6_row13_col5, #T_b4ec6_row13_col6, #T_b4ec6_row13_col7, #T_b4ec6_row13_col8, #T_b4ec6_row13_col9, #T_b4ec6_row13_col10, #T_b4ec6_row14_col0, #T_b4ec6_row14_col1, #T_b4ec6_row14_col2, #T_b4ec6_row14_col3, #T_b4ec6_row14_col4, #T_b4ec6_row14_col5, #T_b4ec6_row14_col6, #T_b4ec6_row14_col7, #T_b4ec6_row14_col8, #T_b4ec6_row14_col9, #T_b4ec6_row14_col10 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b4ec6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b4ec6_level0_col0\" class=\"col_heading level0 col0\" >Pub id</th>\n",
       "      <th id=\"T_b4ec6_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_b4ec6_level0_col2\" class=\"col_heading level0 col2\" >Country</th>\n",
       "      <th id=\"T_b4ec6_level0_col3\" class=\"col_heading level0 col3\" >Gender</th>\n",
       "      <th id=\"T_b4ec6_level0_col4\" class=\"col_heading level0 col4\" >Field</th>\n",
       "      <th id=\"T_b4ec6_level0_col5\" class=\"col_heading level0 col5\" >c-index</th>\n",
       "      <th id=\"T_b4ec6_level0_col6\" class=\"col_heading level0 col6\" >Country factor</th>\n",
       "      <th id=\"T_b4ec6_level0_col7\" class=\"col_heading level0 col7\" >Gender factor</th>\n",
       "      <th id=\"T_b4ec6_level0_col8\" class=\"col_heading level0 col8\" >Field factor</th>\n",
       "      <th id=\"T_b4ec6_level0_col9\" class=\"col_heading level0 col9\" >Paper factor</th>\n",
       "      <th id=\"T_b4ec6_level0_col10\" class=\"col_heading level0 col10\" >c-index </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_b4ec6_row0_col0\" class=\"data row0 col0\" >0540609372</td>\n",
       "      <td id=\"T_b4ec6_row0_col1\" class=\"data row0 col1\" >Adam</td>\n",
       "      <td id=\"T_b4ec6_row0_col2\" class=\"data row0 col2\" >Italy</td>\n",
       "      <td id=\"T_b4ec6_row0_col3\" class=\"data row0 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row0_col4\" class=\"data row0 col4\" >Health</td>\n",
       "      <td id=\"T_b4ec6_row0_col5\" class=\"data row0 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row0_col6\" class=\"data row0 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row0_col7\" class=\"data row0 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row0_col8\" class=\"data row0 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row0_col9\" class=\"data row0 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row0_col10\" class=\"data row0 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_b4ec6_row1_col0\" class=\"data row1 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row1_col1\" class=\"data row1 col1\" >Adam</td>\n",
       "      <td id=\"T_b4ec6_row1_col2\" class=\"data row1 col2\" >Italy</td>\n",
       "      <td id=\"T_b4ec6_row1_col3\" class=\"data row1 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row1_col4\" class=\"data row1 col4\" >Health</td>\n",
       "      <td id=\"T_b4ec6_row1_col5\" class=\"data row1 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row1_col6\" class=\"data row1 col6\" >26.40</td>\n",
       "      <td id=\"T_b4ec6_row1_col7\" class=\"data row1 col7\" >1.96</td>\n",
       "      <td id=\"T_b4ec6_row1_col8\" class=\"data row1 col8\" >9.43</td>\n",
       "      <td id=\"T_b4ec6_row1_col9\" class=\"data row1 col9\" >37.79</td>\n",
       "      <td id=\"T_b4ec6_row1_col10\" class=\"data row1 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_b4ec6_row2_col0\" class=\"data row2 col0\" >1319112586</td>\n",
       "      <td id=\"T_b4ec6_row2_col1\" class=\"data row2 col1\" >Adam</td>\n",
       "      <td id=\"T_b4ec6_row2_col2\" class=\"data row2 col2\" >Italy</td>\n",
       "      <td id=\"T_b4ec6_row2_col3\" class=\"data row2 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row2_col4\" class=\"data row2 col4\" >Health</td>\n",
       "      <td id=\"T_b4ec6_row2_col5\" class=\"data row2 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row2_col6\" class=\"data row2 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row2_col7\" class=\"data row2 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row2_col8\" class=\"data row2 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row2_col9\" class=\"data row2 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row2_col10\" class=\"data row2 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row3\" class=\"row_heading level0 row3\" >13</th>\n",
       "      <td id=\"T_b4ec6_row3_col0\" class=\"data row3 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row3_col1\" class=\"data row3 col1\" >David</td>\n",
       "      <td id=\"T_b4ec6_row3_col2\" class=\"data row3 col2\" >United States</td>\n",
       "      <td id=\"T_b4ec6_row3_col3\" class=\"data row3 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row3_col4\" class=\"data row3 col4\" >Health</td>\n",
       "      <td id=\"T_b4ec6_row3_col5\" class=\"data row3 col5\" >23.05</td>\n",
       "      <td id=\"T_b4ec6_row3_col6\" class=\"data row3 col6\" >7.83</td>\n",
       "      <td id=\"T_b4ec6_row3_col7\" class=\"data row3 col7\" >2.37</td>\n",
       "      <td id=\"T_b4ec6_row3_col8\" class=\"data row3 col8\" >12.86</td>\n",
       "      <td id=\"T_b4ec6_row3_col9\" class=\"data row3 col9\" >23.05</td>\n",
       "      <td id=\"T_b4ec6_row3_col10\" class=\"data row3 col10\" >18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_b4ec6_row4_col0\" class=\"data row4 col0\" >0540609372</td>\n",
       "      <td id=\"T_b4ec6_row4_col1\" class=\"data row4 col1\" >Emily</td>\n",
       "      <td id=\"T_b4ec6_row4_col2\" class=\"data row4 col2\" >Cuba</td>\n",
       "      <td id=\"T_b4ec6_row4_col3\" class=\"data row4 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row4_col4\" class=\"data row4 col4\" >Computer Sci</td>\n",
       "      <td id=\"T_b4ec6_row4_col5\" class=\"data row4 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row4_col6\" class=\"data row4 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row4_col7\" class=\"data row4 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row4_col8\" class=\"data row4 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row4_col9\" class=\"data row4 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row4_col10\" class=\"data row4 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row5\" class=\"row_heading level0 row5\" >3</th>\n",
       "      <td id=\"T_b4ec6_row5_col0\" class=\"data row5 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row5_col1\" class=\"data row5 col1\" >Emily</td>\n",
       "      <td id=\"T_b4ec6_row5_col2\" class=\"data row5 col2\" >Cuba</td>\n",
       "      <td id=\"T_b4ec6_row5_col3\" class=\"data row5 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row5_col4\" class=\"data row5 col4\" >Computer Sci</td>\n",
       "      <td id=\"T_b4ec6_row5_col5\" class=\"data row5 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row5_col6\" class=\"data row5 col6\" >26.40</td>\n",
       "      <td id=\"T_b4ec6_row5_col7\" class=\"data row5 col7\" >1.96</td>\n",
       "      <td id=\"T_b4ec6_row5_col8\" class=\"data row5 col8\" >9.43</td>\n",
       "      <td id=\"T_b4ec6_row5_col9\" class=\"data row5 col9\" >37.79</td>\n",
       "      <td id=\"T_b4ec6_row5_col10\" class=\"data row5 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row6\" class=\"row_heading level0 row6\" >4</th>\n",
       "      <td id=\"T_b4ec6_row6_col0\" class=\"data row6 col0\" >1319112586</td>\n",
       "      <td id=\"T_b4ec6_row6_col1\" class=\"data row6 col1\" >Emily</td>\n",
       "      <td id=\"T_b4ec6_row6_col2\" class=\"data row6 col2\" >Cuba</td>\n",
       "      <td id=\"T_b4ec6_row6_col3\" class=\"data row6 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row6_col4\" class=\"data row6 col4\" >Computer Sci</td>\n",
       "      <td id=\"T_b4ec6_row6_col5\" class=\"data row6 col5\" >29.60</td>\n",
       "      <td id=\"T_b4ec6_row6_col6\" class=\"data row6 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row6_col7\" class=\"data row6 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row6_col8\" class=\"data row6 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row6_col9\" class=\"data row6 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row6_col10\" class=\"data row6 col10\" >27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row7\" class=\"row_heading level0 row7\" >12</th>\n",
       "      <td id=\"T_b4ec6_row7_col0\" class=\"data row7 col0\" >0540609372</td>\n",
       "      <td id=\"T_b4ec6_row7_col1\" class=\"data row7 col1\" >Maria</td>\n",
       "      <td id=\"T_b4ec6_row7_col2\" class=\"data row7 col2\" >Mexico</td>\n",
       "      <td id=\"T_b4ec6_row7_col3\" class=\"data row7 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row7_col4\" class=\"data row7 col4\" >Social Sci</td>\n",
       "      <td id=\"T_b4ec6_row7_col5\" class=\"data row7 col5\" >33.49</td>\n",
       "      <td id=\"T_b4ec6_row7_col6\" class=\"data row7 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row7_col7\" class=\"data row7 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row7_col8\" class=\"data row7 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row7_col9\" class=\"data row7 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row7_col10\" class=\"data row7 col10\" >27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_b4ec6_row8_col0\" class=\"data row8 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row8_col1\" class=\"data row8 col1\" >Maria</td>\n",
       "      <td id=\"T_b4ec6_row8_col2\" class=\"data row8 col2\" >Mexico</td>\n",
       "      <td id=\"T_b4ec6_row8_col3\" class=\"data row8 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row8_col4\" class=\"data row8 col4\" >Social Sci</td>\n",
       "      <td id=\"T_b4ec6_row8_col5\" class=\"data row8 col5\" >33.49</td>\n",
       "      <td id=\"T_b4ec6_row8_col6\" class=\"data row8 col6\" >26.40</td>\n",
       "      <td id=\"T_b4ec6_row8_col7\" class=\"data row8 col7\" >1.96</td>\n",
       "      <td id=\"T_b4ec6_row8_col8\" class=\"data row8 col8\" >26.40</td>\n",
       "      <td id=\"T_b4ec6_row8_col9\" class=\"data row8 col9\" >54.76</td>\n",
       "      <td id=\"T_b4ec6_row8_col10\" class=\"data row8 col10\" >27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row9\" class=\"row_heading level0 row9\" >11</th>\n",
       "      <td id=\"T_b4ec6_row9_col0\" class=\"data row9 col0\" >1319112586</td>\n",
       "      <td id=\"T_b4ec6_row9_col1\" class=\"data row9 col1\" >Maria</td>\n",
       "      <td id=\"T_b4ec6_row9_col2\" class=\"data row9 col2\" >Mexico</td>\n",
       "      <td id=\"T_b4ec6_row9_col3\" class=\"data row9 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row9_col4\" class=\"data row9 col4\" >Social Sci</td>\n",
       "      <td id=\"T_b4ec6_row9_col5\" class=\"data row9 col5\" >33.49</td>\n",
       "      <td id=\"T_b4ec6_row9_col6\" class=\"data row9 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row9_col7\" class=\"data row9 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row9_col8\" class=\"data row9 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row9_col9\" class=\"data row9 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row9_col10\" class=\"data row9 col10\" >27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b4ec6_row10_col0\" class=\"data row10 col0\" >3708184030</td>\n",
       "      <td id=\"T_b4ec6_row10_col1\" class=\"data row10 col1\" >Maria</td>\n",
       "      <td id=\"T_b4ec6_row10_col2\" class=\"data row10 col2\" >Mexico</td>\n",
       "      <td id=\"T_b4ec6_row10_col3\" class=\"data row10 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row10_col4\" class=\"data row10 col4\" >Social Sci</td>\n",
       "      <td id=\"T_b4ec6_row10_col5\" class=\"data row10 col5\" >33.49</td>\n",
       "      <td id=\"T_b4ec6_row10_col6\" class=\"data row10 col6\" >21.60</td>\n",
       "      <td id=\"T_b4ec6_row10_col7\" class=\"data row10 col7\" >1.89</td>\n",
       "      <td id=\"T_b4ec6_row10_col8\" class=\"data row10 col8\" >4.70</td>\n",
       "      <td id=\"T_b4ec6_row10_col9\" class=\"data row10 col9\" >28.19</td>\n",
       "      <td id=\"T_b4ec6_row10_col10\" class=\"data row10 col10\" >27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row11\" class=\"row_heading level0 row11\" >8</th>\n",
       "      <td id=\"T_b4ec6_row11_col0\" class=\"data row11 col0\" >0540609372</td>\n",
       "      <td id=\"T_b4ec6_row11_col1\" class=\"data row11 col1\" >Robert</td>\n",
       "      <td id=\"T_b4ec6_row11_col2\" class=\"data row11 col2\" >United States</td>\n",
       "      <td id=\"T_b4ec6_row11_col3\" class=\"data row11 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row11_col4\" class=\"data row11 col4\" >Engineering</td>\n",
       "      <td id=\"T_b4ec6_row11_col5\" class=\"data row11 col5\" >28.37</td>\n",
       "      <td id=\"T_b4ec6_row11_col6\" class=\"data row11 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row11_col7\" class=\"data row11 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row11_col8\" class=\"data row11 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row11_col9\" class=\"data row11 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row11_col10\" class=\"data row11 col10\" >26.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row12\" class=\"row_heading level0 row12\" >6</th>\n",
       "      <td id=\"T_b4ec6_row12_col0\" class=\"data row12 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row12_col1\" class=\"data row12 col1\" >Robert</td>\n",
       "      <td id=\"T_b4ec6_row12_col2\" class=\"data row12 col2\" >United States</td>\n",
       "      <td id=\"T_b4ec6_row12_col3\" class=\"data row12 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row12_col4\" class=\"data row12 col4\" >Engineering</td>\n",
       "      <td id=\"T_b4ec6_row12_col5\" class=\"data row12 col5\" >28.37</td>\n",
       "      <td id=\"T_b4ec6_row12_col6\" class=\"data row12 col6\" >5.74</td>\n",
       "      <td id=\"T_b4ec6_row12_col7\" class=\"data row12 col7\" >1.96</td>\n",
       "      <td id=\"T_b4ec6_row12_col8\" class=\"data row12 col8\" >26.40</td>\n",
       "      <td id=\"T_b4ec6_row12_col9\" class=\"data row12 col9\" >34.10</td>\n",
       "      <td id=\"T_b4ec6_row12_col10\" class=\"data row12 col10\" >26.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row13\" class=\"row_heading level0 row13\" >7</th>\n",
       "      <td id=\"T_b4ec6_row13_col0\" class=\"data row13 col0\" >1319112586</td>\n",
       "      <td id=\"T_b4ec6_row13_col1\" class=\"data row13 col1\" >Robert</td>\n",
       "      <td id=\"T_b4ec6_row13_col2\" class=\"data row13 col2\" >United States</td>\n",
       "      <td id=\"T_b4ec6_row13_col3\" class=\"data row13 col3\" >M</td>\n",
       "      <td id=\"T_b4ec6_row13_col4\" class=\"data row13 col4\" >Engineering</td>\n",
       "      <td id=\"T_b4ec6_row13_col5\" class=\"data row13 col5\" >28.37</td>\n",
       "      <td id=\"T_b4ec6_row13_col6\" class=\"data row13 col6\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row13_col7\" class=\"data row13 col7\" >1.50</td>\n",
       "      <td id=\"T_b4ec6_row13_col8\" class=\"data row13 col8\" >12.00</td>\n",
       "      <td id=\"T_b4ec6_row13_col9\" class=\"data row13 col9\" >25.50</td>\n",
       "      <td id=\"T_b4ec6_row13_col10\" class=\"data row13 col10\" >26.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b4ec6_row14_col0\" class=\"data row14 col0\" >1123345821</td>\n",
       "      <td id=\"T_b4ec6_row14_col1\" class=\"data row14 col1\" >Sophia</td>\n",
       "      <td id=\"T_b4ec6_row14_col2\" class=\"data row14 col2\" >United States</td>\n",
       "      <td id=\"T_b4ec6_row14_col3\" class=\"data row14 col3\" >F</td>\n",
       "      <td id=\"T_b4ec6_row14_col4\" class=\"data row14 col4\" >Computer Sci</td>\n",
       "      <td id=\"T_b4ec6_row14_col5\" class=\"data row14 col5\" >23.05</td>\n",
       "      <td id=\"T_b4ec6_row14_col6\" class=\"data row14 col6\" >7.83</td>\n",
       "      <td id=\"T_b4ec6_row14_col7\" class=\"data row14 col7\" >2.37</td>\n",
       "      <td id=\"T_b4ec6_row14_col8\" class=\"data row14 col8\" >12.86</td>\n",
       "      <td id=\"T_b4ec6_row14_col9\" class=\"data row14 col9\" >23.05</td>\n",
       "      <td id=\"T_b4ec6_row14_col10\" class=\"data row14 col10\" >18.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a719155a450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN EXECUTION BLOCK FOR JUPYTER NOTEBOOK\n",
    "# Load the data\n",
    "df = pd.read_csv('sampleTableV3.csv')\n",
    "\n",
    "# --- PART 1: Define our author cohort by selecting them from a single, representative paper ---\n",
    "# This is the most robust way to get the exact group we want to analyze.\n",
    "pub_id_for_cohort = \"pub.1123345821\"\n",
    "author_cohort = collectAuthorsOfOnePaper(df, pub_id_for_cohort)\n",
    "\n",
    "author_names = [author.getName() for author in author_cohort]\n",
    "print(f\"--- Building a focused table based on a specific author cohort ---\")\n",
    "print(f\"Selected {len(author_cohort)} authors from paper '{pub_id_for_cohort}': {author_names}\\n\")\n",
    "\n",
    "final_table = generate_table_for_author_cohort(author_cohort, df)\n",
    "if final_table:\n",
    "    display(final_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
